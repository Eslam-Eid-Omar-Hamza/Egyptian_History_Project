{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9797dfe",
   "metadata": {},
   "source": [
    "## Data Augmentation and Label Validation\n",
    "\n",
    "To increase dataset balance and improve model generalization, I used Albumentations for data augmentation.  \n",
    "I also validated class consistency to ensure all labels matched the dataset configuration before training.  \n",
    "This helped avoid mismatched IDs and class errors that had previously caused training restarts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4f86c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Augment dataset using Albumentations\n",
    "# This script balances the dataset by generating new images per class until each reaches the target count.\n",
    "\n",
    "import os, cv2, random, shutil\n",
    "from collections import defaultdict\n",
    "import albumentations as A\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# مسارات\n",
    "images_dir = \"/content/drive/MyDrive/dataset_split/train/images\"\n",
    "labels_dir = \"/content/drive/MyDrive/dataset_split/train/labels\"\n",
    "\n",
    "aug_images_dir = \"/content/dataset/train/images_balanced\"\n",
    "aug_labels_dir = \"/content/dataset/train/labels_balanced\"\n",
    "os.makedirs(aug_images_dir, exist_ok=True)\n",
    "os.makedirs(aug_labels_dir, exist_ok=True)\n",
    "\n",
    "# أسماء الكلاسات حسب data.yaml\n",
    "class_names = [\n",
    "    \"Khafre-Pyramid\",\n",
    "    \"Khufu-Pyramid\",\n",
    "    \"Sphinx\",\n",
    "    \"menkaure-pyramid\"\n",
    "]\n",
    "NUM_CLASSES = len(class_names)\n",
    "TARGET_COUNT = 5000  # الهدف: عدد الصور التي تحتوي الكلاس\n",
    "\n",
    "# تحويلات\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Rotate(limit=25, p=0.5),\n",
    "    A.RandomScale(scale_limit=0.2, p=0.5),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.MotionBlur(p=0.3)\n",
    "], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"], min_visibility=0.2))\n",
    "\n",
    "def yolo_to_voc(parts, img_w, img_h):\n",
    "    cls, x_c, y_c, w, h = map(float, parts)\n",
    "    x_min = max(0, int((x_c - w/2) * img_w))\n",
    "    y_min = max(0, int((y_c - h/2) * img_h))\n",
    "    x_max = min(img_w-1, int((x_c + w/2) * img_w))\n",
    "    y_max = min(img_h-1, int((y_c + h/2) * img_h))\n",
    "    return int(cls), x_min, y_min, x_max, y_max\n",
    "\n",
    "def voc_to_yolo(cls, x_min, y_min, x_max, y_max, img_w, img_h):\n",
    "    x_c = (x_min + x_max) / 2 / img_w\n",
    "    y_c = (y_min + y_max) / 2 / img_h\n",
    "    w = (x_max - x_min) / img_w\n",
    "    h = (y_max - y_min) / img_h\n",
    "    return f\"{cls} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\"\n",
    "\n",
    "# --- 1) فهرسة الداتا الأصلية ونسخها إلى مجلد balanced ---\n",
    "# نجمع كل الصور والليبلز مع كل البوكسات (لكل الكلاسات)\n",
    "image_index = {}  # img_path -> {\"label_path\":..., \"boxes\":[(cls, xmin,ymin,xmax,ymax)]}\n",
    "class_to_images = defaultdict(set)  # cls_id -> set(img_name)\n",
    "\n",
    "for lbl_name in os.listdir(labels_dir):\n",
    "    if not lbl_name.endswith(\".txt\"):\n",
    "        continue\n",
    "    label_path = os.path.join(labels_dir, lbl_name)\n",
    "    img_name_base = os.path.splitext(lbl_name)[0]\n",
    "\n",
    "    # جرّب امتدادات شائعة\n",
    "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        img_path = os.path.join(images_dir, img_name_base + ext)\n",
    "        if os.path.exists(img_path):\n",
    "            break\n",
    "    else:\n",
    "        continue  # مفيش صورة مطابقة\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    boxes = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        cls_id = int(parts[0])\n",
    "        cls_id = max(0, min(cls_id, NUM_CLASSES-1))\n",
    "        _, x_min, y_min, x_max, y_max = yolo_to_voc(parts, w, h)\n",
    "        if x_max > x_min and y_max > y_min:\n",
    "            boxes.append((cls_id, x_min, y_min, x_max, y_max))\n",
    "\n",
    "    if not boxes:\n",
    "        continue\n",
    "\n",
    "    image_index[img_path] = {\"label_path\": label_path, \"boxes\": boxes}\n",
    "\n",
    "    # نسخ الأصل للمجلد المتوازن باسم ثابت\n",
    "    out_img_name = img_name_base + \".jpg\"  # نوحّد الامتداد\n",
    "    out_lbl_name = img_name_base + \".txt\"\n",
    "    cv2.imwrite(os.path.join(aug_images_dir, out_img_name), img)\n",
    "\n",
    "    with open(os.path.join(aug_labels_dir, out_lbl_name), \"w\") as f:\n",
    "        for (cid, x1, y1, x2, y2) in boxes:\n",
    "            f.write(voc_to_yolo(cid, x1, y1, x2, y2, w, h) + \"\\n\")\n",
    "\n",
    "    # حدّث صور-لكل-كلاس (Presence per image)\n",
    "    present_cls = set(cid for cid, *_ in boxes)\n",
    "    for cid in present_cls:\n",
    "        class_to_images[cid].add(out_img_name)\n",
    "\n",
    "# طباعة عدد الصور الأصلية لكل كلاس\n",
    "print(\" الصور (presence) لكل كلاس بعد نسخ الأصل:\")\n",
    "for cid in range(NUM_CLASSES):\n",
    "    print(f\"{class_names[cid]}: {len(class_to_images[cid])}\")\n",
    "\n",
    "# --- 2) عمل Augment حتى نصل TARGET_COUNT presence لكل كلاس ---\n",
    "all_source_imgs = list(image_index.keys())\n",
    "\n",
    "def save_augmented(aug_img, aug_bboxes, aug_labels, base_name):\n",
    "    H, W = aug_img.shape[:2]\n",
    "    out_img = f\"{base_name}.jpg\"\n",
    "    out_lbl = f\"{base_name}.txt\"\n",
    "    cv2.imwrite(os.path.join(aug_images_dir, out_img), aug_img)\n",
    "    with open(os.path.join(aug_labels_dir, out_lbl), \"w\") as f:\n",
    "        for (x1, y1, x2, y2), lbl in zip(aug_bboxes, aug_labels):\n",
    "            cls_id = class_names.index(lbl)\n",
    "            f.write(voc_to_yolo(cls_id, int(x1), int(y1), int(x2), int(y2), W, H) + \"\\n\")\n",
    "    return out_img, out_lbl\n",
    "\n",
    "# خرائط من id -> اسم لابيل\n",
    "id_to_name = {i: n for i, n in enumerate(class_names)}\n",
    "\n",
    "# نحتاج اسماء فريدة للملفات\n",
    "global_counter = 0\n",
    "\n",
    "for target_cid in range(NUM_CLASSES):\n",
    "    needed = max(0, TARGET_COUNT - len(class_to_images[target_cid]))\n",
    "    print(f\"\\n Augmenting for class [{class_names[target_cid]}], need: {needed}\")\n",
    "    if needed == 0:\n",
    "        continue\n",
    "\n",
    "    # اختَر فقط الصور التي تحتوي الكلاس الهدف لتكون منطلق الـaugment\n",
    "    sources = [p for p, info in image_index.items() if any(b[0] == target_cid for b in info[\"boxes\"])]\n",
    "    if not sources:\n",
    "        print(f\" لا توجد صور تحتوي {class_names[target_cid]} أصلاً، تخطي.\")\n",
    "        continue\n",
    "\n",
    "    attempts = 0\n",
    "    max_attempts = needed * 30  # هام: سقف للمحاولات\n",
    "    while needed > 0 and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        src_img_path = random.choice(sources)\n",
    "        src = cv2.imread(src_img_path)\n",
    "        if src is None:\n",
    "            continue\n",
    "        H, W = src.shape[:2]\n",
    "\n",
    "        # حضّر كل البوكسات (لكل الكلاسات) مع أسماء الكلاسات\n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        for (cid, x1, y1, x2, y2) in image_index[src_img_path][\"boxes\"]:\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            labels.append(id_to_name[cid])\n",
    "\n",
    "        # طبّق التحويل\n",
    "        try:\n",
    "            t = transform(image=src, bboxes=bboxes, class_labels=labels)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        aug_img = t[\"image\"]\n",
    "        aug_bboxes = t[\"bboxes\"]\n",
    "        aug_labels = t[\"class_labels\"]\n",
    "\n",
    "        if not aug_bboxes:\n",
    "            continue\n",
    "\n",
    "        # تأكد أن الصورة الناتجة مازالت تحتوي الكلاس الهدف\n",
    "        present_cls_after = set(class_names.index(lbl) for lbl in aug_labels)\n",
    "        if target_cid not in present_cls_after:\n",
    "            continue\n",
    "\n",
    "        base_name = f\"{class_names[target_cid]}_aug_{global_counter}\"\n",
    "        out_img_name, _ = save_augmented(aug_img, aug_bboxes, aug_labels, base_name)\n",
    "        global_counter += 1\n",
    "\n",
    "        # حدّث عدّ الصور presence لكل كلاس بناءً على الصورة الجديدة\n",
    "        for cls_here in present_cls_after:\n",
    "            class_to_images[cls_here].add(out_img_name)\n",
    "\n",
    "        needed = max(0, TARGET_COUNT - len(class_to_images[target_cid]))\n",
    "\n",
    "    if needed > 0:\n",
    "        print(f\" لم نصل للهدف لكلاس {class_names[target_cid]}. باقي: {needed}. جرّب زيادة التنوع أو مصادر أكثر.\")\n",
    "\n",
    "print(\"\\n انتهى التوازن بالـpresence per class (صور تحتوي الكلاس).\")\n",
    "for cid in range(NUM_CLASSES):\n",
    "    print(f\"{class_names[cid]}: {len(class_to_images[cid])} / {TARGET_COUNT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f33a79",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 🖼️ Step 2: Visualize Augmented Images\n",
    "import cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show example image with bounding boxes\n",
    "img_path = \"/content/drive/MyDrive/dataset_split/train/images/example.jpg\"\n",
    "lbl_path = img_path.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "with open(lbl_path) as f:\n",
    "    for line in f:\n",
    "        cls, x_c, y_c, bw, bh = map(float, line.strip().split())\n",
    "        x1 = int((x_c - bw/2) * w)\n",
    "        y1 = int((y_c - bh/2) * h)\n",
    "        x2 = int((x_c + bw/2) * w)\n",
    "        y2 = int((y_c + bh/2) * h)\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Augmented Image with Bounding Boxes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98843ec8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  Step 3: Validate class IDs and label consistency\n",
    "\n",
    "import os, random\n",
    "\n",
    "labels_dir = \"/content/drive/MyDrive/dataset_split/train/labels\"\n",
    "class_names = [\"Khafre-Pyramid\", \"Khufu-Pyramid\", \"Sphinx\", \"Menkaure-Pyramid\"]\n",
    "\n",
    "ids_seen = set()\n",
    "for i, fn in enumerate(random.sample([f for f in os.listdir(labels_dir) if f.endswith('.txt')], k=10)):\n",
    "    with open(os.path.join(labels_dir, fn)) as f:\n",
    "        for ln in f:\n",
    "            cid = int(ln.split()[0])\n",
    "            assert 0 <= cid < len(class_names), f\"Label ID خارج المدى: {cid} في {fn}\"\n",
    "            ids_seen.add(cid)\n",
    "\n",
    "print(\"✅ Label IDs are valid and match data.yaml configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c64045",
   "metadata": {},
   "source": [
    "### ✅ Results\n",
    "- Each class was balanced to approximately 5000 images using Albumentations.\n",
    "- Verified that all label IDs matched the `data.yaml` configuration.\n",
    "- Visual inspection confirmed bounding boxes remained accurate after augmentation.\n",
    "\n",
    "This process fixed a previous issue where mismatched label IDs caused YOLO to crash during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883f4dc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
